---
globs: src/combo_dl/problems/*.py
---

# Problem Development Guidelines

## Problem Interface
All problems must inherit from [BaseProblem](mdc:src/combo_dl/problems/base_problem.py) and implement:

```python
@abstractmethod
def reward(self, x: torch.Tensor) -> torch.Tensor:
    """Compute the score for each solution in the batch. Higher is better.
    
    Args:
        x: Tensor of shape (batch_size, *)
    
    Returns:
        Tensor of shape (batch_size, *) with rewards
    """

@abstractmethod
def is_valid_solution(self, solution: torch.Tensor) -> torch.Tensor:
    """Whether each element in the batch is a valid solution to the problem. Batched."""
```

## Problem Patterns

### Constructor Pattern
- Store problem parameters as instance variables
- Set `goal_score` attribute for early stopping if applicable
- Validate input parameters

### Reward Function
- **Higher is better**: Design reward functions so higher values indicate better solutions
- **Batch Processing**: Handle batched inputs efficiently
- **Tensor Operations**: Use PyTorch operations for GPU acceleration
- **Gradient Flow**: Ensure reward computation supports backpropagation

### Validation
- Implement `is_valid_solution()` for constraint checking
- Use vectorized operations for batch validation
- Return boolean tensors matching input batch size

### Early Stopping
- Implement `get_goal_score()` to return target score or None
- Use `should_stop_early()` for early stopping logic
- Provide meaningful stop reasons

## Graph Problem Specifics
- Use NetworkX for graph operations when needed
- Convert between different graph representations (adjacency matrices, edge lists)
- Handle graph isomorphism and canonical forms
- Use PyTorch Geometric for graph neural network integration

## Example Problem Structure
```python
class MyProblem(BaseProblem):
    def __init__(self, param1: int, param2: float, goal_score: float = None):
        self.param1 = param1
        self.param2 = param2
        self.goal_score = goal_score
        
    def reward(self, x: torch.Tensor) -> torch.Tensor:
        # Compute rewards for batch of solutions
        return rewards
        
    def is_valid_solution(self, solution: torch.Tensor) -> torch.Tensor:
        # Check validity for each solution in batch
        return validity_mask
```

## Integration with Algorithms
- Problems are instantiated via Hydra configuration
- Algorithms call `problem.reward()` and `problem.is_valid_solution()`
- Use problem's early stopping methods in optimization loops